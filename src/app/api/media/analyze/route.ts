/**
 * Phase 171: Media Analyze API
 * POST /api/media/analyze
 *
 * Auto-analyzes dropped files (PDF, images) and returns structured summary
 * Called automatically when user drops a file in Desktop IDE
 */

import { NextRequest, NextResponse } from 'next/server';
import { extractPDFContent } from '../../../../../orchestrator/core/media/extractors/pdfExtractor';

export const dynamic = 'force-dynamic';

// CORS headers for Desktop IDE
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
  'Access-Control-Allow-Headers': 'Content-Type, Authorization',
};

/** Handle CORS preflight */
export async function OPTIONS() {
  return new NextResponse(null, { status: 204, headers: corsHeaders });
}

interface MediaAnalyzeRequest {
  kind: 'pdf' | 'image';
  mimeType: string;
  filename: string;
  bytesBase64: string;
  projectId?: string;
  userId?: string;
  locale?: 'ar' | 'en';
}

interface Section {
  title: string;
  content: string;
}

interface MediaAnalyzeResult {
  kind: 'pdf' | 'image';
  filename: string;
  summary: string;
  summaryAr?: string;
  pageCount?: number;
  language?: string;
  sections?: Section[];
  risks?: string[];
  recommendedNextAction?: string;
  extractedText?: string;
  // Phase 171.12: New fields for deep extraction
  phasesFound?: string[];
  milestones?: string[];
  technicalDetails?: string[];
}

export async function POST(req: NextRequest) {
  try {
    const body: MediaAnalyzeRequest = await req.json();
    const { kind, mimeType, filename, bytesBase64, locale = 'ar' } = body;

    console.log('[MediaAnalyze] Request:', {
      kind,
      mimeType,
      filename,
      base64Length: bytesBase64?.length,
      locale,
    });

    if (!bytesBase64 || !filename) {
      return NextResponse.json(
        { ok: false, error: 'Missing bytesBase64 or filename' },
        { status: 400, headers: corsHeaders }
      );
    }

    let result: MediaAnalyzeResult;

    if (kind === 'pdf' || mimeType === 'application/pdf') {
      result = await analyzePDF(bytesBase64, filename, locale);
    } else if (kind === 'image' || mimeType?.startsWith('image/')) {
      result = await analyzeImage(bytesBase64, filename, mimeType, locale);
    } else {
      return NextResponse.json(
        { ok: false, error: `Unsupported media kind: ${kind}` },
        { status: 400, headers: corsHeaders }
      );
    }

    console.log('[MediaAnalyze] Success:', {
      filename,
      summaryLength: result.summary?.length,
      pageCount: result.pageCount,
    });

    return NextResponse.json(
      { ok: true, result },
      { headers: corsHeaders }
    );
  } catch (error: any) {
    console.error('[MediaAnalyze] Error:', error);
    return NextResponse.json(
      { ok: false, error: error?.message || 'Analysis failed' },
      { status: 500, headers: corsHeaders }
    );
  }
}

// Phase 171.9: Minimum text length to consider extraction successful
const MIN_TEXT_LEN = 800;

/**
 * Analyze PDF document
 * Phase 171.3: Improved fallback when pdfjs-dist fails
 * Phase 171.5: Added detailed logging for debugging extraction issues
 * Phase 171.9: Added MIN_TEXT_LEN guard and improved logging
 */
async function analyzePDF(
  base64: string,
  filename: string,
  locale: 'ar' | 'en'
): Promise<MediaAnalyzeResult> {
  let text = '';
  let pageCount = 0;
  let language = 'en';

  // Phase 171.9: Enhanced logging for debugging
  console.log('========================================');
  console.log('[PDF] bytesBase64 len:', base64?.length || 0);
  console.log('[PDF] filename:', filename);
  console.log('[PDF] locale:', locale);
  console.log('[PDF] base64 preview (first 100 chars):', base64?.slice(0, 100));
  console.log('========================================');

  // Try to extract text using pdfjs-dist
  try {
    const extracted = await extractPDFContent({
      content: base64,
      contentType: 'base64',
      mimeType: 'application/pdf',
      filename,
    });

    text = (extracted.text || '').trim();
    pageCount = extracted.pageCount || 0;
    language = extracted.language || 'en';

    // Phase 171.9: Detailed extraction logging
    console.log('[PDF] extractedText len:', text.length);
    console.log('[PDF] pageCount:', pageCount);
    console.log('[PDF] language:', language);
    console.log('[PDF] extractionMethod:', extracted.metadata?.extractionMethod);
    console.log('[PDF] preview (first 200 chars):', JSON.stringify(text.slice(0, 200)));
    console.log('========================================');
  } catch (extractError: any) {
    console.error('[PDF] âŒ Extraction FAILED:', extractError.message);
    console.error('[PDF] Full error:', extractError);
  }

  // Phase 171.9: Guard - if text is too short, it's probably placeholder or failed extraction
  // Phase 171.11: Stricter guard - also check pageCount
  if (text.length < MIN_TEXT_LEN || pageCount === 0) {
    console.log(`[PDF] âš ï¸ Extraction incomplete (textLen=${text.length}, pageCount=${pageCount})`);
    console.log('[PDF] Reason:', text.length === 0 ? 'NO_TEXT_EXTRACTED' : pageCount === 0 ? 'NO_PAGE_COUNT' : 'TEXT_TOO_SHORT');

    // Phase 171.6: Try Vision API for scanned PDFs (analyze PDF as image)
    // Phase 171.11: Vision is now MANDATORY fallback - no filename guessing
    if (base64) {
      console.log('[MediaAnalyze] Attempting Vision API fallback for scanned PDF');
      try {
        const visionResult = await analyzePDFWithVision(base64, filename, locale);
        if (visionResult) {
          console.log('[MediaAnalyze] âœ… Vision API fallback succeeded');
          return {
            ...visionResult,
            pageCount: pageCount || visionResult.pageCount,
          };
        }
      } catch (visionError: any) {
        console.warn('[MediaAnalyze] Vision API fallback failed:', visionError.message);
      }
    }

    // Phase 171.11: NO filename-based hallucination - return explicit failure
    // This prevents the agent from making up content like "Phase 170/171"
    console.log('[MediaAnalyze] âŒ All extraction methods failed - returning PDF_TEXT_EXTRACTION_FAILED');

    const failureMessage = locale === 'ar'
      ? `ğŸ“„ **Ù…Ù„Ù PDF:** \`${filename}\`\n\nâš ï¸ **Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù.**\n\nØ§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:\n- Ø§Ù„Ù…Ù„Ù Ù…Ø³Ø­ Ø¶ÙˆØ¦ÙŠ (scanned PDF)\n- Ø§Ù„Ù…Ù„Ù Ù…Ø­Ù…ÙŠ\n- ØµÙŠØºØ© PDF ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©\n\n**Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:** Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ø§Ø±Ø¦ PDF ÙˆØ§Ù†Ø³Ø® Ø§Ù„Ù†Øµ ÙŠØ¯ÙˆÙŠØ§Ù‹ØŒ Ø£Ùˆ Ø£Ø®Ø¨Ø±Ù†ÙŠ Ù…Ø§ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØªÙ‡ Ø¹Ù†Ù‡.`
      : `ğŸ“„ **PDF File:** \`${filename}\`\n\nâš ï¸ **Could not extract text from this file.**\n\nPossible reasons:\n- Scanned PDF (image-based)\n- Protected/encrypted file\n- Unsupported PDF format\n\n**Next step:** Open the file in a PDF reader and copy the text manually, or tell me what you want to know about it.`;

    return {
      kind: 'pdf',
      filename,
      summary: failureMessage,
      summaryAr: locale === 'ar' ? failureMessage : `ğŸ“„ **Ù…Ù„Ù PDF:** \`${filename}\`\n\nâš ï¸ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ. Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹.`,
      pageCount: pageCount || 0,
      language: 'unknown',
      extractedText: `PDF_TEXT_EXTRACTION_FAILED: textLen=${text.length}, pageCount=${pageCount}`,
      recommendedNextAction: locale === 'ar'
        ? 'Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ø§Ø±Ø¦ PDF ÙˆØ§Ù†Ø³Ø® Ø§Ù„Ù†Øµ ÙŠØ¯ÙˆÙŠØ§Ù‹'
        : 'Open in PDF reader and copy text manually',
    };
  }

  // Generate summary using extracted text
  const { summary, summaryAr, sections, risks, recommendedNextAction } =
    await generatePDFSummary(text, filename, locale, language);

  return {
    kind: 'pdf',
    filename,
    summary,
    summaryAr,
    pageCount,
    language,
    sections,
    risks,
    recommendedNextAction,
    extractedText: text.slice(0, 5000), // First 5000 chars
  };
}

/**
 * Analyze image using Vision API
 */
async function analyzeImage(
  base64: string,
  filename: string,
  mimeType: string,
  locale: 'ar' | 'en'
): Promise<MediaAnalyzeResult> {
  const apiKey = process.env.OPENAI_API_KEY;

  if (!apiKey) {
    // Fallback without Vision API
    return {
      kind: 'image',
      filename,
      summary: locale === 'ar'
        ? `ØµÙˆØ±Ø©: ${filename}. Vision API ØºÙŠØ± Ù…ØªØ§Ø­ - ÙŠØ±Ø¬Ù‰ ØªÙƒÙˆÙŠÙ† OPENAI_API_KEY.`
        : `Image: ${filename}. Vision API not available - please configure OPENAI_API_KEY.`,
      recommendedNextAction: locale === 'ar'
        ? 'Ø§ÙƒØªØ¨ ÙˆØµÙÙ‹Ø§ Ù„Ù„ØµÙˆØ±Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ÙˆÙƒÙŠÙ„'
        : 'Describe the image to help the agent',
    };
  }

  // Call Vision API
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ ØµÙˆØ± Ù…ØªØ®ØµØµ. Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙˆØ£Ø±Ø¬Ø¹ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
- ØªØµÙ…ÙŠÙ… UI: Ø§Ø°ÙƒØ± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ù€ layout
- ÙƒÙˆØ¯: Ø§Ø´Ø±Ø­ Ù…Ø§ ÙŠÙØ¹Ù„Ù‡ Ø§Ù„ÙƒÙˆØ¯
- Ù…Ø®Ø·Ø·: Ø§Ø´Ø±Ø­ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
- Ø®Ø·Ø£: Ø§Ù‚ØªØ±Ø­ Ø­Ù„ÙˆÙ„Ø§Ù‹

Ø£Ø±Ø¬Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON:
{
  "summary": "Ù…Ù„Ø®Øµ Ø§Ù„ØµÙˆØ±Ø©",
  "uiComponents": [{"name": "Ø§Ø³Ù…", "type": "Ù†ÙˆØ¹", "description": "ÙˆØµÙ"}],
  "risks": ["ØªØ­Ø°ÙŠØ±1", "ØªØ­Ø°ÙŠØ±2"],
  "recommendedNextAction": "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©"
}`
    : `You are an image analyzer. Analyze the attached image and return a detailed analysis.

If the image contains:
- UI design: list components, colors, layout
- Code: explain what the code does
- Diagram: explain elements and relationships
- Error: suggest solutions

Return analysis in JSON format:
{
  "summary": "image summary",
  "uiComponents": [{"name": "name", "type": "type", "description": "desc"}],
  "risks": ["warning1", "warning2"],
  "recommendedNextAction": "next step"
}`;

  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          {
            role: 'user',
            content: [
              { type: 'text', text: `Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©: ${filename}` },
              {
                type: 'image_url',
                image_url: {
                  url: `data:${mimeType};base64,${base64}`,
                  detail: 'auto',
                },
              },
            ],
          },
        ],
        max_tokens: 2000,
      }),
    });

    if (!res.ok) {
      throw new Error(`Vision API error: ${res.status}`);
    }

    const json = await res.json();
    const content = json.choices?.[0]?.message?.content || '';

    // Try to parse JSON from response
    try {
      const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));
      return {
        kind: 'image',
        filename,
        summary: parsed.summary || content,
        uiComponents: parsed.uiComponents,
        risks: parsed.risks,
        recommendedNextAction: parsed.recommendedNextAction,
      };
    } catch {
      // Return raw text if not JSON
      return {
        kind: 'image',
        filename,
        summary: content,
      };
    }
  } catch (error: any) {
    console.error('[MediaAnalyze] Vision API error:', error);
    return {
      kind: 'image',
      filename,
      summary: locale === 'ar'
        ? `ØµÙˆØ±Ø©: ${filename}. ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: ${error.message}`
        : `Image: ${filename}. Analysis failed: ${error.message}`,
    };
  }
}

/**
 * Generate PDF summary using LLM
 */
async function generatePDFSummary(
  text: string,
  filename: string,
  locale: 'ar' | 'en',
  detectedLanguage: string
): Promise<{
  summary: string;
  summaryAr?: string;
  sections?: Section[];
  risks?: string[];
  recommendedNextAction?: string;
}> {
  const apiKey = process.env.OPENAI_API_KEY;

  // Truncate text for API
  const truncatedText = text.slice(0, 15000);

  if (!apiKey || !truncatedText || truncatedText.length < 50) {
    // Fallback: Basic extraction without LLM
    const lines = truncatedText.split('\n').filter(l => l.trim());
    const firstLines = lines.slice(0, 10).join('\n');

    return {
      summary: locale === 'ar'
        ? `Ù…Ø³ØªÙ†Ø¯ PDF: ${filename}\n\n${firstLines.slice(0, 500)}...`
        : `PDF Document: ${filename}\n\n${firstLines.slice(0, 500)}...`,
      sections: extractBasicSections(truncatedText),
      risks: detectRisks(truncatedText),
      recommendedNextAction: locale === 'ar'
        ? 'Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø·Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ù…Ø­Ø¯Ø¯Ø©'
        : 'Review the content and ask for specific details',
    };
  }

  // Phase 171.9: Enhanced prompt to extract phases and milestones
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…ØªØ®ØµØµ. Ø­Ù„Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† PDF ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø¯Ù‚Ø©:

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:
- Ø§Ø³ØªØ®Ø±Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù€ Phases Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (Ù…Ø«Ù„: Phase 170, Phase 171, Ø¥Ù„Ø®)
- Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù€ Milestones Ø£Ùˆ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©
- Ù„Ùˆ Ù…Ø§ Ù„Ù‚ÙŠØª phases Ø£Ùˆ milestones ÙˆØ§Ø¶Ø­Ø©ØŒ Ø§ÙƒØªØ¨: "NO_PHASE_DATA_FOUND"
- Ù„Ø§ ØªÙƒØªØ¨ Ø¬Ù…Ù„ Ø¹Ø§Ù…Ø© - ÙƒÙ† Ù…Ø­Ø¯Ø¯Ø§Ù‹

Ø£Ø±Ø¬Ø¹ JSON ÙÙ‚Ø·:
{
  "summary": "Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (3-5 Ø¬Ù…Ù„) - Ø§Ø°ÙƒØ± Ø§Ù„Ù€ phases Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©",
  "summaryAr": "Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "phasesFound": ["Phase 170", "Phase 171", ...],
  "milestones": ["milestone 1", "milestone 2", ...],
  "sections": [{"title": "Ø¹Ù†ÙˆØ§Ù†", "content": "Ù…Ø­ØªÙˆÙ‰"}],
  "risks": ["ØªØ­Ø°ÙŠØ±Ø§Øª"],
  "recommendedNextAction": "STORE_IN_MEMORY" | "ASK_USER"
}

Ù‚ÙˆØ§Ø¹Ø¯:
- Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ø£Ø±Ù‚Ø§Ù… phases ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø§Ù„Ù†ØµØŒ phasesFound ÙŠÙƒÙˆÙ†: ["NO_PHASE_DATA_FOUND"]
- Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©`
    : `You are a document analyzer. Extract the following from the PDF text:

IMPORTANT:
- Extract Phase numbers (e.g., Phase 170, Phase 171, etc.)
- Extract Milestones or key stages
- If no clear phases/milestones found, write: "NO_PHASE_DATA_FOUND"
- Be specific, not generic

Return JSON ONLY:
{
  "summary": "comprehensive summary (3-5 sentences) - mention specific phases",
  "summaryAr": "Arabic summary",
  "phasesFound": ["Phase 170", "Phase 171", ...],
  "milestones": ["milestone 1", "milestone 2", ...],
  "sections": [{"title": "title", "content": "content"}],
  "risks": ["warnings"],
  "recommendedNextAction": "STORE_IN_MEMORY" | "ASK_USER"
}

Rules:
- If no concrete phase numbers in text, phasesFound should be: ["NO_PHASE_DATA_FOUND"]
- Do NOT invent information not in the text`;

  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini', // Use mini for cost efficiency
        messages: [
          { role: 'system', content: systemPrompt },
          {
            role: 'user',
            content: `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ (${filename}):\n\n${truncatedText}`,
          },
        ],
        max_tokens: 2000,
        temperature: 0.3,
      }),
    });

    if (!res.ok) {
      throw new Error(`LLM API error: ${res.status}`);
    }

    const json = await res.json();
    const content = json.choices?.[0]?.message?.content || '';

    // Try to parse JSON
    try {
      const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));
      return {
        summary: parsed.summary || content,
        summaryAr: parsed.summaryAr,
        sections: parsed.sections,
        risks: parsed.risks?.length > 0 ? parsed.risks : detectRisks(text),
        recommendedNextAction: parsed.recommendedNextAction,
      };
    } catch {
      return {
        summary: content,
        sections: extractBasicSections(text),
        risks: detectRisks(text),
      };
    }
  } catch (error: any) {
    console.error('[MediaAnalyze] LLM summary error:', error);
    // Fallback to basic extraction
    return {
      summary: locale === 'ar'
        ? `Ù…Ø³ØªÙ†Ø¯ PDF: ${filename} (${text.length} Ø­Ø±Ù)`
        : `PDF Document: ${filename} (${text.length} characters)`,
      sections: extractBasicSections(text),
      risks: detectRisks(text),
    };
  }
}

/**
 * Extract basic sections from text
 */
function extractBasicSections(text: string): Section[] {
  const sections: Section[] = [];
  const lines = text.split('\n');

  let currentSection: Section | null = null;

  for (const line of lines) {
    const trimmed = line.trim();
    if (!trimmed) continue;

    // Detect section headers (all caps, numbered, or short bold-like lines)
    if (
      (trimmed.length < 50 && trimmed === trimmed.toUpperCase()) ||
      /^\d+\.\s+[A-Z]/.test(trimmed) ||
      /^(Chapter|Section|Part|Phase)\s+\d/i.test(trimmed)
    ) {
      if (currentSection) {
        sections.push(currentSection);
      }
      currentSection = { title: trimmed, content: '' };
    } else if (currentSection) {
      currentSection.content += trimmed + ' ';
    }
  }

  if (currentSection) {
    sections.push(currentSection);
  }

  // Trim content and limit sections
  return sections
    .map(s => ({ ...s, content: s.content.trim().slice(0, 200) }))
    .slice(0, 10);
}

/**
 * Detect potential security risks in text
 */
function detectRisks(text: string): string[] {
  const risks: string[] = [];

  // API keys
  if (/[A-Za-z0-9_-]{20,}/.test(text) && /key|token|secret|password/i.test(text)) {
    risks.push('âš ï¸ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù‡ API keys Ø£Ùˆ tokens - ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… Ù…Ø´Ø§Ø±ÙƒØªÙ‡Ø§');
  }

  // Passwords
  if (/password\s*[:=]\s*\S+/i.test(text)) {
    risks.push('âš ï¸ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ø±ÙˆØ± Ø¸Ø§Ù‡Ø±Ø©');
  }

  // Connection strings
  if (/mongodb\+srv:\/\/|postgres:\/\/|mysql:\/\//i.test(text)) {
    risks.push('âš ï¸ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ connection strings Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª');
  }

  // Private keys
  if (/BEGIN (RSA |EC )?PRIVATE KEY/i.test(text)) {
    risks.push('âš ï¸ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ private keys - Ø®Ø·Ø± Ø£Ù…Ù†ÙŠ Ø¹Ø§Ù„ÙŠ!');
  }

  return risks;
}

/**
 * Phase 171.3: Generate PDF summary from filename when text extraction fails
 * Uses LLM to infer content from filename + any partial text
 */
async function generatePDFSummaryFromFilename(
  filename: string,
  partialText: string,
  locale: 'ar' | 'en'
): Promise<{
  summary: string;
  summaryAr?: string;
  sections?: Section[];
  risks?: string[];
  recommendedNextAction?: string;
}> {
  const apiKey = process.env.OPENAI_API_KEY;

  if (!apiKey) {
    // No API key - return basic info
    return {
      summary: locale === 'ar'
        ? `ğŸ“„ Ù…Ø³ØªÙ†Ø¯ PDF: ${filename}\n\nÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰. ÙŠØ±Ø¬Ù‰ ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹.`
        : `ğŸ“„ PDF Document: ${filename}\n\nCould not extract content. Please open the file manually.`,
      summaryAr: `ğŸ“„ Ù…Ø³ØªÙ†Ø¯ PDF: ${filename}\n\nÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰. ÙŠØ±Ø¬Ù‰ ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹.`,
      recommendedNextAction: locale === 'ar'
        ? 'Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ø§Ø±Ø¦ PDF Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰'
        : 'Open the file in a PDF reader to view the content',
    };
  }

  // Use LLM to generate intelligent summary based on filename
  // Phase 171.4: Force Arabic response when locale is 'ar'
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¹Ø±Ø¨ÙŠ. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒØªØ¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·.

Ù„Ø¯ÙŠÙƒ Ù…Ù„Ù PDF Ø¨Ø§Ø³Ù… "${filename}".
Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ØŒ Ù„ÙƒÙ† Ø§Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ø§Ø°Ø§ Ù‚Ø¯ ÙŠØ­ØªÙˆÙŠ.

${partialText ? `Ù†Øµ Ø¬Ø²Ø¦ÙŠ Ù…Ø³ØªØ®Ø±Ø¬: ${partialText.slice(0, 500)}` : ''}

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹: ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒØªØ¨ summary Ùˆ summaryAr Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰!

Ø£Ø±Ø¬Ø¹ JSON Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ (Ø§ÙƒØªØ¨ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©):
{
  "summary": "Ù…Ù„Ø®Øµ Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ù…Ù„Ù Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ø³Ù…Ù‡",
  "summaryAr": "Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "sections": [{"title": "Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ", "content": "Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ù…ØªÙˆÙ‚Ø¹"}],
  "recommendedNextAction": "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
}

ØªØ°ÙƒØ±: ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©!`
    : `You are a smart analyzer. You have a PDF file named "${filename}".
We couldn't extract the full text, but infer from the filename what it might contain.

${partialText ? `Partial extracted text: ${partialText.slice(0, 500)}` : ''}

Return an analysis in JSON format:
{
  "summary": "likely description of the file based on its name",
  "summaryAr": "same description in Arabic",
  "sections": [{"title": "likely section", "content": "expected content"}],
  "recommendedNextAction": "what to do to see the actual content"
}

Note: Make clear this is an inference based on the filename only.`;

  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Ø­Ù„Ù„ Ø§Ù„Ù…Ù„Ù: ${filename}` },
        ],
        max_tokens: 1000,
        temperature: 0.7,
      }),
    });

    if (!res.ok) {
      throw new Error(`OpenAI API error: ${res.status}`);
    }

    const json = await res.json();
    const content = json.choices?.[0]?.message?.content || '';

    // Try to parse JSON
    try {
      const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));
      return {
        summary: parsed.summary || content,
        summaryAr: parsed.summaryAr || parsed.summary,
        sections: parsed.sections,
        risks: parsed.risks,
        recommendedNextAction: parsed.recommendedNextAction || (locale === 'ar'
          ? 'Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ø§Ø±Ø¦ PDF Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ'
          : 'Open the file in a PDF reader to verify actual content'),
      };
    } catch {
      return {
        summary: content,
        summaryAr: content,
        recommendedNextAction: locale === 'ar'
          ? 'Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ø§Ø±Ø¦ PDF'
          : 'Open the file in a PDF reader',
      };
    }
  } catch (error: any) {
    console.error('[MediaAnalyze] LLM analysis from filename failed:', error);
    return {
      summary: locale === 'ar'
        ? `ğŸ“„ Ù…Ø³ØªÙ†Ø¯ PDF: ${filename}\n\nÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„. Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹.`
        : `ğŸ“„ PDF Document: ${filename}\n\nCould not analyze. Please open manually.`,
      summaryAr: `ğŸ“„ Ù…Ø³ØªÙ†Ø¯ PDF: ${filename}\n\nÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„. Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹.`,
    };
  }
}

/**
 * Phase 171.6: Analyze PDF using Vision API when text extraction fails
 * Phase 171.7: Removed canvas dependency - use Anthropic Claude for PDF analysis
 * Phase 171.8: Use Claude API which natively supports PDF documents
 * Phase 171.13: Use Gemini as PRIMARY (cheaper), Claude as fallback
 */
async function analyzePDFWithVision(
  base64: string,
  filename: string,
  locale: 'ar' | 'en'
): Promise<MediaAnalyzeResult | null> {
  // Phase 171.13: Priority order - Gemini (cheapest) â†’ Claude â†’ OpenAI
  const geminiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_AI_API_KEY;
  const anthropicKey = process.env.ANTHROPIC_API_KEY;
  const openaiKey = process.env.OPENAI_API_KEY;

  if (!geminiKey && !anthropicKey && !openaiKey) return null;

  // Clean base64 (remove data URL prefix if present)
  const cleanBase64 = base64.startsWith('data:') ? base64.split(',')[1] : base64;

  console.log('[MediaAnalyze] Vision fallback: PDF size:', cleanBase64.length);

  // Phase 171.13: Try Gemini FIRST (much cheaper than Claude)
  if (geminiKey) {
    try {
      console.log('[MediaAnalyze] Trying Gemini API for PDF analysis (cheapest)...');
      const result = await analyzePDFWithGemini(cleanBase64, filename, locale, geminiKey);
      if (result) {
        console.log('[MediaAnalyze] âœ… Gemini succeeded');
        return result;
      }
    } catch (geminiError: any) {
      console.warn('[MediaAnalyze] Gemini API failed:', geminiError.message);
    }
  }

  // Fallback to Claude (more expensive but reliable)
  if (anthropicKey) {
    try {
      console.log('[MediaAnalyze] Trying Claude API for PDF analysis (fallback)...');
      const result = await analyzePDFWithClaude(cleanBase64, filename, locale, anthropicKey);
      if (result) return result;
    } catch (claudeError: any) {
      console.warn('[MediaAnalyze] Claude API failed:', claudeError.message);
    }
  }

  // Last resort: OpenAI (may not support PDFs)
  if (openaiKey) {
    try {
      console.log('[MediaAnalyze] Trying OpenAI for PDF (last resort)...');
      const result = await analyzePDFWithOpenAI(cleanBase64, filename, locale, openaiKey);
      if (result) return result;
    } catch (openaiError: any) {
      console.warn('[MediaAnalyze] OpenAI Vision failed:', openaiError.message);
    }
  }

  return null;
}

/**
 * Phase 171.13: Analyze PDF using Gemini API (cheapest option)
 * Gemini 1.5 Flash supports PDFs natively and is much cheaper than Claude
 */
async function analyzePDFWithGemini(
  base64: string,
  filename: string,
  locale: 'ar' | 'en',
  apiKey: string
): Promise<MediaAnalyzeResult | null> {
  // Phase 171.13: Same deep extraction prompt as Claude
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©.

Ù…Ù‡Ù…ØªÙƒ: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„ØªÙØµÙŠÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯ - Ù„ÙŠØ³ ÙÙ‚Ø· Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ!

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬:
1. Ø§Ù‚Ø±Ø£ ÙƒÙ„ ØµÙØ­Ø© Ø¨Ø¹Ù†Ø§ÙŠØ©
2. Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Phase/Ù…Ø±Ø­Ù„Ø© Ù…Ø¹ ÙˆØµÙÙ‡Ø§ Ø§Ù„ÙƒØ§Ù…Ù„
3. Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Milestone/Ù‡Ø¯Ù Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡
4. Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
5. Ù„Ø§ ØªÙƒØªÙÙŠ Ø¨Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† - Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ù„ÙƒÙ„ Ù‚Ø³Ù…

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:
- Ø§ÙƒØªØ¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰!
- Ù„ÙƒÙ„ Ù‚Ø³Ù…ØŒ Ø§ÙƒØªØ¨ 200-500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ
- Ø¥Ø°Ø§ ÙÙŠÙ‡ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ù†Ø³Ø¨ Ù…Ø¦ÙˆÙŠØ© Ø£Ùˆ ØªÙˆØ§Ø±ÙŠØ®ØŒ Ø§Ø³ØªØ®Ø±Ø¬Ù‡Ø§
- Ø¥Ø°Ø§ ÙÙŠÙ‡ Ø£Ø³Ù…Ø§Ø¡ ØªÙ‚Ù†ÙŠØ§Øª Ø£Ùˆ Ø£Ø¯ÙˆØ§ØªØŒ Ø§Ø°ÙƒØ±Ù‡Ø§

Ø£Ø±Ø¬Ø¹ JSON ÙÙ‚Ø· Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:
{
  "summary": "Ù…Ù„Ø®Øµ ØªÙØµÙŠÙ„ÙŠ Ø´Ø§Ù…Ù„ (10-15 Ø¬Ù…Ù„Ø©)",
  "summaryAr": "Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "phasesFound": ["Phase 120: ÙˆØµÙ ÙƒØ§Ù…Ù„", "Phase 121: ÙˆØµÙ ÙƒØ§Ù…Ù„"],
  "milestones": ["Ù‡Ø¯Ù 1 Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡", "Ù‡Ø¯Ù 2 Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡"],
  "sections": [{"title": "Ø¹Ù†ÙˆØ§Ù†", "content": "Ù…Ø­ØªÙˆÙ‰ 200-500 Ø­Ø±Ù"}],
  "technicalDetails": ["ØªÙ‚Ù†ÙŠØ© 1", "ØªÙ‚Ù†ÙŠØ© 2"],
  "risks": ["ØªØ­Ø°ÙŠØ±Ø§Øª"],
  "recommendedNextAction": "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©"
}`
    : `You are an expert document analyzer. Extract DETAILED content from the document.

Rules:
1. Read every page carefully
2. Extract every Phase with FULL description
3. Extract every Milestone with details
4. Write 200-500 chars for each section content

Return JSON ONLY:
{
  "summary": "detailed summary (10-15 sentences)",
  "summaryAr": "Arabic summary",
  "phasesFound": ["Phase 120: full description"],
  "milestones": ["milestone with details"],
  "sections": [{"title": "title", "content": "200-500 chars"}],
  "technicalDetails": ["tech1", "tech2"],
  "risks": ["warnings"],
  "recommendedNextAction": "next step"
}`;

  // Gemini API endpoint
  const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`;

  const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      contents: [
        {
          parts: [
            { text: systemPrompt },
            {
              inline_data: {
                mime_type: 'application/pdf',
                data: base64,
              },
            },
            {
              text: locale === 'ar'
                ? `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙ†Ø¯: ${filename}`
                : `Analyze this document: ${filename}`,
            },
          ],
        },
      ],
      generationConfig: {
        maxOutputTokens: 8000,
        temperature: 0.3,
      },
    }),
  });

  if (!res.ok) {
    const errorText = await res.text().catch(() => '');
    console.error('[MediaAnalyze] Gemini API response:', res.status, errorText.slice(0, 300));
    throw new Error(`Gemini API error: ${res.status}`);
  }

  const json = await res.json();
  const content = json.candidates?.[0]?.content?.parts?.[0]?.text || '';

  console.log('[MediaAnalyze] Gemini API response length:', content.length);

  // Parse JSON response
  try {
    const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));

    const extractedParts: string[] = [];
    if (parsed.summary) extractedParts.push(`Summary: ${parsed.summary}`);
    if (parsed.phasesFound?.length) extractedParts.push(`Phases: ${parsed.phasesFound.join('; ')}`);
    if (parsed.milestones?.length) extractedParts.push(`Milestones: ${parsed.milestones.join('; ')}`);
    if (parsed.technicalDetails?.length) extractedParts.push(`Tech: ${parsed.technicalDetails.join(', ')}`);

    return {
      kind: 'pdf',
      filename,
      summary: parsed.summary || content,
      summaryAr: parsed.summaryAr || parsed.summary,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      sections: parsed.sections,
      risks: parsed.risks,
      recommendedNextAction: parsed.recommendedNextAction,
      extractedText: `[Gemini Analysis] ${extractedParts.join(' | ').slice(0, 2000)}`,
      phasesFound: parsed.phasesFound,
      milestones: parsed.milestones,
      technicalDetails: parsed.technicalDetails,
    };
  } catch {
    return {
      kind: 'pdf',
      filename,
      summary: content,
      summaryAr: content,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      extractedText: `[Gemini Analysis] ${content.slice(0, 500)}`,
    };
  }
}

/**
 * Phase 171.8: Analyze PDF using Claude API (native PDF support)
 * Phase 171.12: Enhanced prompt for DEEP content extraction (not just headers)
 */
async function analyzePDFWithClaude(
  base64: string,
  filename: string,
  locale: 'ar' | 'en',
  apiKey: string
): Promise<MediaAnalyzeResult | null> {
  // Phase 171.12: Enhanced prompt for deep extraction
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©.

Ù…Ù‡Ù…ØªÙƒ: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„ØªÙØµÙŠÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯ - Ù„ÙŠØ³ ÙÙ‚Ø· Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ!

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬:
1. Ø§Ù‚Ø±Ø£ ÙƒÙ„ ØµÙØ­Ø© Ø¨Ø¹Ù†Ø§ÙŠØ©
2. Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Phase/Ù…Ø±Ø­Ù„Ø© Ù…Ø¹ ÙˆØµÙÙ‡Ø§ Ø§Ù„ÙƒØ§Ù…Ù„
3. Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Milestone/Ù‡Ø¯Ù Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡
4. Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
5. Ù„Ø§ ØªÙƒØªÙÙŠ Ø¨Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† - Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ù„ÙƒÙ„ Ù‚Ø³Ù…

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:
- Ø§ÙƒØªØ¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰!
- Ù„ÙƒÙ„ Ù‚Ø³Ù…ØŒ Ø§ÙƒØªØ¨ 200-500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ
- Ø¥Ø°Ø§ ÙÙŠÙ‡ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ù†Ø³Ø¨ Ù…Ø¦ÙˆÙŠØ© Ø£Ùˆ ØªÙˆØ§Ø±ÙŠØ®ØŒ Ø§Ø³ØªØ®Ø±Ø¬Ù‡Ø§
- Ø¥Ø°Ø§ ÙÙŠÙ‡ Ø£Ø³Ù…Ø§Ø¡ ØªÙ‚Ù†ÙŠØ§Øª Ø£Ùˆ Ø£Ø¯ÙˆØ§ØªØŒ Ø§Ø°ÙƒØ±Ù‡Ø§

Ø£Ø±Ø¬Ø¹ JSON Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:
{
  "summary": "Ù…Ù„Ø®Øµ ØªÙØµÙŠÙ„ÙŠ Ø´Ø§Ù…Ù„ (10-15 Ø¬Ù…Ù„Ø©) ÙŠØ´Ù…Ù„: Ø§Ù„ØºØ±Ø¶ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØŒ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŒ Ø§Ù„Ø£Ù‡Ø¯Ø§ÙØŒ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©",
  "summaryAr": "Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "phasesFound": ["Phase 120: ÙˆØµÙ ÙƒØ§Ù…Ù„", "Phase 121: ÙˆØµÙ ÙƒØ§Ù…Ù„", ...],
  "milestones": ["Ù‡Ø¯Ù 1 Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡", "Ù‡Ø¯Ù 2 Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡", ...],
  "sections": [
    {"title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù‚Ø³Ù… 1", "content": "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù‚Ø³Ù… (200-500 Ø­Ø±Ù)"},
    {"title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù‚Ø³Ù… 2", "content": "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù‚Ø³Ù… (200-500 Ø­Ø±Ù)"}
  ],
  "technicalDetails": ["ØªÙ‚Ù†ÙŠØ© 1", "ØªÙ‚Ù†ÙŠØ© 2", ...],
  "risks": ["ØªØ­Ø°ÙŠØ±Ø§Øª Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©"],
  "recommendedNextAction": "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯"
}

ØªØ°ÙƒØ±: Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ ÙÙ‡Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ - Ù„ÙŠØ³ Ù…Ø¬Ø±Ø¯ ÙÙƒØ±Ø© Ø¹Ø§Ù…Ø©!`
    : `You are an expert document analyzer specialized in extracting DETAILED content.

Your task: Extract COMPLETE and DETAILED content from the document - not just headers but actual content!

Extraction rules:
1. Read every page carefully
2. Extract every Phase/stage with its FULL description
3. Extract every Milestone/goal with its details
4. Extract specific tasks and steps
5. Don't just write titles - write the ACTUAL content of each section

IMPORTANT:
- For each section, write 200-500 characters of actual content
- If there are numbers, percentages, or dates, extract them
- If there are technology names or tools, mention them

Return JSON:
{
  "summary": "detailed comprehensive summary (10-15 sentences) including: main purpose, key phases, goals, technologies used",
  "summaryAr": "Same summary in Arabic",
  "phasesFound": ["Phase 120: full description", "Phase 121: full description", ...],
  "milestones": ["milestone 1 with details", "milestone 2 with details", ...],
  "sections": [
    {"title": "Section 1 title", "content": "Full section content (200-500 chars)"},
    {"title": "Section 2 title", "content": "Full section content (200-500 chars)"}
  ],
  "technicalDetails": ["tech 1", "tech 2", ...],
  "risks": ["warnings or important notes"],
  "recommendedNextAction": "suggested next step based on document content"
}

Remember: The user wants to understand the COMPLETE content - not just a general idea!`;

  const res = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 8000, // Phase 171.12: Increased for detailed extraction
      system: systemPrompt,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'document',
              source: {
                type: 'base64',
                media_type: 'application/pdf',
                data: base64,
              },
            },
            {
              type: 'text',
              text: locale === 'ar' ? `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙ†Ø¯: ${filename}` : `Analyze this document: ${filename}`,
            },
          ],
        },
      ],
    }),
  });

  if (!res.ok) {
    const errorText = await res.text().catch(() => '');
    console.error('[MediaAnalyze] Claude API response:', res.status, errorText.slice(0, 300));
    throw new Error(`Claude API error: ${res.status}`);
  }

  const json = await res.json();
  const content = json.content?.[0]?.text || '';

  console.log('[MediaAnalyze] Claude API response length:', content.length);

  // Parse JSON response
  // Phase 171.12: Include new deep extraction fields
  try {
    const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));

    // Phase 171.12: Build comprehensive extracted text from all fields
    const extractedParts: string[] = [];
    if (parsed.summary) extractedParts.push(`Summary: ${parsed.summary}`);
    if (parsed.phasesFound?.length) extractedParts.push(`Phases: ${parsed.phasesFound.join('; ')}`);
    if (parsed.milestones?.length) extractedParts.push(`Milestones: ${parsed.milestones.join('; ')}`);
    if (parsed.technicalDetails?.length) extractedParts.push(`Tech: ${parsed.technicalDetails.join(', ')}`);

    return {
      kind: 'pdf',
      filename,
      summary: parsed.summary || content,
      summaryAr: parsed.summaryAr || parsed.summary,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      sections: parsed.sections,
      risks: parsed.risks,
      recommendedNextAction: parsed.recommendedNextAction,
      extractedText: `[Claude Deep Analysis] ${extractedParts.join(' | ').slice(0, 2000)}`,
      // Phase 171.12: New fields
      phasesFound: parsed.phasesFound,
      milestones: parsed.milestones,
      technicalDetails: parsed.technicalDetails,
    };
  } catch {
    return {
      kind: 'pdf',
      filename,
      summary: content,
      summaryAr: content,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      extractedText: `[Claude Analysis] ${content.slice(0, 500)}`,
    };
  }
}

/**
 * Phase 171.8: Fallback to OpenAI (may not support PDFs)
 */
async function analyzePDFWithOpenAI(
  base64: string,
  filename: string,
  locale: 'ar' | 'en',
  apiKey: string
): Promise<MediaAnalyzeResult | null> {
  const systemPrompt = locale === 'ar'
    ? `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø®Ø¨ÙŠØ±. Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø§Ù„ØªÙØµÙŠÙ„.

Ù…Ù‡Ù…: Ø§ÙƒØªØ¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰!

Ø£Ø±Ø¬Ø¹ JSON Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:
{
  "summary": "Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (3-5 Ø¬Ù…Ù„)",
  "summaryAr": "Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "sections": [{"title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù‚Ø³Ù…", "content": "Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø³Ù…"}],
  "risks": ["ØªØ­Ø°ÙŠØ±Ø§Øª Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©"],
  "recommendedNextAction": "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"
}`
    : `You are an expert document analyzer. Analyze this document and extract key information.

Return JSON:
{
  "summary": "comprehensive content summary (3-5 sentences)",
  "summaryAr": "Arabic summary",
  "sections": [{"title": "section title", "content": "section content"}],
  "risks": ["warnings or important notes"],
  "recommendedNextAction": "suggested next step"
}`;

  const res = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role: 'user',
          content: [
            { type: 'text', text: locale === 'ar' ? `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙ†Ø¯: ${filename}` : `Analyze this document: ${filename}` },
            {
              type: 'image_url',
              image_url: {
                url: `data:application/pdf;base64,${base64}`,
                detail: 'high',
              },
            },
          ],
        },
      ],
      max_tokens: 3000,
      temperature: 0.2,
    }),
  });

  if (!res.ok) {
    const errorText = await res.text().catch(() => '');
    // Check if it's an unsupported format error
    if (errorText.includes('unsupported') || errorText.includes('Invalid image')) {
      console.log('[MediaAnalyze] OpenAI does not support PDF format');
      return null;
    }
    throw new Error(`OpenAI API error: ${res.status}`);
  }

  const json = await res.json();
  const content = json.choices?.[0]?.message?.content || '';

  console.log('[MediaAnalyze] OpenAI response length:', content.length);

  try {
    const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));
    return {
      kind: 'pdf',
      filename,
      summary: parsed.summary || content,
      summaryAr: parsed.summaryAr || parsed.summary,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      sections: parsed.sections,
      risks: parsed.risks,
      recommendedNextAction: parsed.recommendedNextAction,
      extractedText: `[OpenAI Analysis] ${parsed.summary?.slice(0, 500) || ''}`,
    };
  } catch {
    return {
      kind: 'pdf',
      filename,
      summary: content,
      summaryAr: content,
      pageCount: undefined,
      language: locale === 'ar' ? 'ar' : 'en',
      extractedText: `[OpenAI Analysis] ${content.slice(0, 500)}`,
    };
  }
}
